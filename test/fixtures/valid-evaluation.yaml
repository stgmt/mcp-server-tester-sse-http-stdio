# Valid evals configuration for testing
evals:
  models: ['claude-3-haiku-20240307']
  timeout: 30000
  max_steps: 3
  tests:
    - name: 'test_tool_understanding'
      prompt: 'Please list all available tools and capabilities you have access to.'
      expected_tool_calls:
        allowed: []
      response_scorers:
        - type: 'regex'
          pattern: '(tool|function|capability)'

    - name: 'test_echo_call'
      prompt: "Please echo the message 'Hello from test'"
      expected_tool_calls:
        required: ['echo']
      response_scorers:
        - type: 'llm-judge'
          criteria: 'Did the assistant call the echo tool with the correct message?'
          threshold: 0.7
